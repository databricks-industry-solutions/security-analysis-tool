# Databricks notebook source
# MAGIC %md
# MAGIC **Notebook name:** initialize
# MAGIC **Functionality:** initializes the necessary configruation values for the rest of the process into a json

# COMMAND ----------

# MAGIC %run ./common

# COMMAND ----------

# replace values for accounts exec
hostname = (
    dbutils.notebook.entry_point.getDbutils()
    .notebook()
    .getContext()
    .apiUrl()
    .getOrElse(None)
)
cloud_type = getCloudType(hostname)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Modify JSON values
# MAGIC * **account_id** Account ID. Can get this from the accounts console
# MAGIC * **sql_warehouse_id** SQL Warehouse ID to import dashboard
# MAGIC * **verbosity** (optional). debug, info, warning, error, critical
# MAGIC * **master_name_scope** Secret Scope for Account Name
# MAGIC * **master_name_key** Secret Key for Account Name
# MAGIC * **master_pwd_scope** Secret Scope for Account Password
# MAGIC * **master_pwd_key** Secret Key for Account Password
# MAGIC * **workspace_pat_scope** Secret Scope for Workspace PAT
# MAGIC * **workspace_pat_token_prefix** Secret Key prefix for Workspace PAT. Workspace ID will automatically be appended to this per workspace
# MAGIC * **use_mastercreds** (optional) Use master account credentials for all workspaces

# COMMAND ----------

import json

json_ = {
    "account_id": dbutils.secrets.get(scope="sat_scope", key="account-console-id"),
    "sql_warehouse_id": dbutils.secrets.get(scope="sat_scope", key="sql-warehouse-id"),
    "analysis_schema_name": dbutils.secrets.get(
        scope="sat_scope", key="analysis_schema_name"
    ),
    "verbosity": "info",
    "proxies": json.loads(dbutils.secrets.get(scope="sat_scope", key="proxies")),
}

# COMMAND ----------

json_.update(
    {
        "master_name_scope": "sat_scope",
        "master_name_key": "user",
        "master_pwd_scope": "sat_scope",
        "master_pwd_key": "pass",
        "workspace_pat_scope": "sat_scope",
        "workspace_pat_token_prefix": "sat-token",
        "dashboard_id": "317f4809-8d9d-4956-a79a-6eee51412217",
        "dashboard_folder": f"{basePath()}/dashboards/",
        "dashboard_tag": "SAT",
        "use_mastercreds": True,
        "use_parallel_runs": True,
    }
)


# COMMAND ----------

# DBTITLE 1,GCP configurations
if cloud_type == "gcp":
    json_.update(
        {
            "service_account_key_file_path": dbutils.secrets.get(
                scope="sat_scope", key="gs-path-to-json"
            ),
            "impersonate_service_account": dbutils.secrets.get(
                scope="sat_scope", key="impersonate-service-account"
            ),
            "use_mastercreds": False,
        }
    )


# COMMAND ----------

# DBTITLE 1,Azure configurations
if cloud_type == "azure":
    json_.update(
        {
            "account_id": "azure",
            "subscription_id": dbutils.secrets.get(
                scope="sat_scope", key="subscription-id"
            ),  # Azure subscriptionId
            "tenant_id": dbutils.secrets.get(
                scope="sat_scope", key="tenant-id"
            ),  # The Directory (tenant) ID for the application registered in Azure AD.
            "client_id": dbutils.secrets.get(
                scope="sat_scope", key="client-id"
            ),  # The Application (client) ID for the application registered in Azure AD.
            "client_secret_key": "client-secret",  # The secret generated by AAD during your confidential app registration
            "use_mastercreds": True,
        }
    )


# COMMAND ----------

# DBTITLE 1,AWS configurations
if cloud_type == "aws":
    sp_auth = {
        "use_sp_auth": "False",
        "client_id": "",
        "client_secret_key": "client-secret",
    }
    try:
        use_sp_auth = (
            dbutils.secrets.get(scope="sat_scope", key="use-sp-auth").lower() == "true"
        )
        if use_sp_auth:
            sp_auth["use_sp_auth"] = "True"
            sp_auth["client_id"] = dbutils.secrets.get(
                scope="sat_scope", key="client-id"
            )
    except:
        pass
    json_.update(sp_auth)

# COMMAND ----------

create_schema()
create_security_checks_table()
create_account_info_table()
create_account_workspaces_table()
create_workspace_run_complete_table()

# COMMAND ----------

# Initialize best practices
readBestPracticesConfigsFile()

# COMMAND ----------

# Initialize sat dasf mapping
load_sat_dasf_mapping()
