{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61ef22c-1a72-497c-b02a-f228f99d5dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh \n",
    "pip install requests-cache\n",
    "curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /tmp\n",
    "echo \"detectors:\n",
    "    - name: DkeaToken\n",
    "      keywords:\n",
    "        - dkea\n",
    "      regex:\n",
    "        id: (?i)\\b(dkea[a-h0-9]{32})\n",
    "    - name: DapiToken\n",
    "      keywords:\n",
    "        - dapi\n",
    "      regex:\n",
    "        id: (?i)\\b(dapi[a-h0-9]{32})\n",
    "    - name: DoseToken\n",
    "      keywords:\n",
    "        - dose\n",
    "      regex:\n",
    "        id: (?i)\\b(dose[a-h0-9]{32}) \" > /tmp/tuf.conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f00897-f0be-4e8d-b8da-f91c3cfa088a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, requests, time, json, base64, subprocess, hashlib, re\n",
    "from datetime import timedelta, datetime\n",
    "from urllib.parse import quote\n",
    "\n",
    "faketoken = \"dkea12345678901234567890123456789012\"\n",
    "\n",
    "# Extract token and API URL from Databricks notebook context\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "base_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().getOrElse(None)\n",
    "\n",
    "\n",
    "def convert_time_to_databricks_format(env_time):\n",
    "    # Assuming env_time is in milliseconds\n",
    "    return int(env_time)\n",
    "\n",
    "def get_yesterday_utc_midnight():\n",
    "    # Get yesterday's date in UTC with a time of 00:00\n",
    "    today_utc_midnight = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    yesterday_utc_midnight = today_utc_midnight - timedelta(days=1)\n",
    "    return int(yesterday_utc_midnight.timestamp() * 1000)\n",
    "\n",
    "def make_request(url, headers, data):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, json=data)\n",
    "        if response.status_code == 200:\n",
    "            json_response = response.json()\n",
    "            print(json_response)\n",
    "            return json_response\n",
    "        else:\n",
    "            print(f\"URL: {url}, gave response code: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_sha(secret):\n",
    "    # Encode the secret string to bytes\n",
    "    secret_bytes = secret.encode(\"utf-8\")\n",
    "\n",
    "    # Create a SHA-256 hash object\n",
    "    sha = hashlib.sha256()\n",
    "\n",
    "    # Update the hash object with the secret bytes\n",
    "    sha.update(secret_bytes)\n",
    "\n",
    "    # Get the hexadecimal representation of the digest\n",
    "    sha_hex = sha.hexdigest()\n",
    "\n",
    "    return sha_hex\n",
    "\n",
    "\n",
    "def get_notebook_permissions(object_id):\n",
    "    try:\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        url = f\"{base_url}/api/2.0/permissions/notebooks/{object_id}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 403:\n",
    "            print(f\"Permission Denied for notebook {object_id}: {url}\")\n",
    "        response.raise_for_status()  # Raise an exception for 4xx and 5xx status codes\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error getting notebook for {object_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def export_notebook_content(notebook_path):\n",
    "    try:\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        url = f\"{base_url}/api/2.0/workspace/export?path={notebook_path}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for 4xx and 5xx status codes\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error exporting notebook content for {notebook_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def decode_and_write_content(content, output_path):\n",
    "    decoded_content = base64.b64decode(content).decode(\"utf-8\")\n",
    "    with open(output_path, \"w\") as file:\n",
    "        file.write(decoded_content)\n",
    "\n",
    "\n",
    "def scan_for_secrets(file_path):\n",
    "    trufflehog_command = f\"/tmp/trufflehog filesystem {file_path} --exclude-detectors DatabricksToken --no-update --config /tmp/tuf.conf -j\"\n",
    "    try:\n",
    "        result = subprocess.run(trufflehog_command, shell=True, check=True, capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Trufflehog: {e}\")\n",
    "        print(e.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Check if notebook is deleted or not.\n",
    "def check_notebook_status(notebook_path):\n",
    "    check_url = f\"{base_url}/api/2.0/workspace/get-status?path={notebook_path}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(check_url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code in (404, 403):\n",
    "            return e.response.status_code\n",
    "        else:\n",
    "            return f\"Error: Unexpected status code - {e.response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n",
    "    return response.status_code\n",
    "\n",
    "# Define a function to check secret presence and call dummy function\n",
    "def check_secret_presence(notebook_path, object_id):\n",
    "    try:\n",
    "        notebook_status = check_notebook_status(notebook_path)\n",
    "\n",
    "        if notebook_status == 200:\n",
    "            export_response = export_notebook_content(notebook_path)\n",
    "            if export_response is not None:\n",
    "                content = export_response[\"content\"]\n",
    "                output_file_path = output_path + f\"/notebook_content_{object_id}.txt\"\n",
    "                decode_and_write_content(content, output_file_path)\n",
    "                print(f\"Notebook content successfully exported to {output_file_path}\")\n",
    "\n",
    "                # Scan for secrets using Trufflehog\n",
    "                trufflehog_output = scan_for_secrets(output_file_path)\n",
    "                if trufflehog_output is not None:\n",
    "                    # Process Trufflehog output\n",
    "                    results = process_trufflehog_output(trufflehog_output)\n",
    "                    print(\"RESULTS\\n\" + json.dumps(results, indent=4))\n",
    "                    \n",
    "        elif notebook_status == 403:\n",
    "            print(f\"Getting a Not authorized error for {notebook_path} : {notebook_status} \")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting notebook content for {notebook_path}: {str(e)}\")\n",
    "\n",
    "def scan_for_secrets(file_path):\n",
    "    trufflehog_command = f\"/tmp/trufflehog filesystem {file_path} --exclude-detectors DatabricksToken --no-update --config /tmp/tuf.conf -j\"\n",
    "    try:\n",
    "        result = subprocess.run(trufflehog_command, shell=True, check=True, capture_output=True, text=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Trufflehog: {e}\")\n",
    "        print(e.stderr)\n",
    "        return None\n",
    "\n",
    "def process_trufflehog_output(trufflehog_output):\n",
    "    results = []\n",
    "    for line in trufflehog_output.splitlines():\n",
    "        data = json.loads(line)\n",
    "        detector_name = data[\"DetectorName\"]\n",
    "        raw_value = data[\"Raw\"]\n",
    "        raw_sha = generate_sha(raw_value)\n",
    "        encoded = raw_sha[0:round(len(raw_sha)*.2)]\n",
    "        results.append({\"DetectorName\": detector_name, \"Raw_SHA\": raw_sha})\n",
    "    return results\n",
    "\n",
    "def process_response(response, results_list, output_filename):\n",
    "    if response:\n",
    "        results = response.get(\"results\", [])\n",
    "        for notebook in results:\n",
    "            notebook_id = notebook.get(\"id\", \"\")\n",
    "            notebook_name = notebook.get(\"name\", \"\")\n",
    "            parent_path = notebook.get(\"workspace_path\", \"\")\n",
    "\n",
    "            temp_path = f\"{parent_path}/{notebook_name}\"\n",
    "            path = quote(temp_path)\n",
    "            print(notebook_id, notebook_name, temp_path)\n",
    "            \n",
    "            if output_filename:\n",
    "              results_list.append({\"object_id\": notebook_id, \"path\": path})\n",
    "\n",
    "              # Write the result to the output file as soon as it's processed\n",
    "              with open(output_filename, mode=\"a\") as output_file:\n",
    "                  json.dump({\"object_id\": notebook_id, \"path\": path}, output_file)\n",
    "                  output_file.write(\"\\n\")\n",
    "            check_secret_presence(path, notebook_id)\n",
    "\n",
    "        # Use None as the default value for nextPageKey\n",
    "        return response.get(\"next_page_token\")\n",
    "\n",
    "    # Return None for an empty response\n",
    "    return None\n",
    "\n",
    "# Get time from environment variable or use today's date in UTC midnight if not provided\n",
    "env_time = int(os.environ.get(\"TIME\", get_yesterday_utc_midnight()))\n",
    "\n",
    "# Convert time to Databricks format\n",
    "last_edited_after = convert_time_to_databricks_format(env_time)\n",
    "\n",
    "# Storing a log of notebooks that were found\n",
    "output_filename = \"/tmp/test_file.json\" # Disabling for testing\n",
    "\n",
    "# Where to write temp notebooks to\n",
    "output_path = \"/tmp/notebooks\"\n",
    "if output_path and not os.path.exists(output_path):\n",
    "  os.mkdir(output_path)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "# Initial request (using GET) without pageKey\n",
    "url = f\"{base_url}/api/2.0/search-midtier/unified-search\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"query\": {\"query\": \"\"},\n",
    "    \"filters\": {\"result_types\": [\"NOTEBOOK\"], \"last_edited_after\": last_edited_after},\n",
    "    \"page_size\": 50,\n",
    "}\n",
    "\n",
    "next_page_key = \"\"  # Initial value is an empty string\n",
    "while next_page_key is not None:\n",
    "    # Add next_page_key to data for subsequent requests\n",
    "    data[\"page_token\"] = next_page_key\n",
    "    print(datetime.now())\n",
    "    # Make request\n",
    "    response = make_request(url, headers, data)\n",
    "    time.sleep(\n",
    "        10\n",
    "    )  # Sleeping for 10 second before making other API call, requirement from global search team to prevent rate limiting.\n",
    "    next_page_key = process_response(response, results_list, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ddf9ac-81a3-439a-a9b3-8498583231fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh ls -l /tmp/notebooks"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1828314051772642,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "trufflehog_scan",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
