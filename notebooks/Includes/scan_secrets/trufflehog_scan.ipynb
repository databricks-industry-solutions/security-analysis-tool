{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61ef22c-1a72-497c-b02a-f228f99d5dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TruffleHog Secret Scanner for Databricks Notebooks\n",
    "\n",
    "## Overview\n",
    "This notebook scans Databricks workspace notebooks for exposed secrets using TruffleHog. It integrates with the Security Analysis Tool (SAT) to provide comprehensive secret detection across your Databricks environment.\n",
    "\n",
    "## Features\n",
    "- Scans all notebooks modified within a specified timeframe\n",
    "- Uses custom detectors for Databricks-specific tokens\n",
    "- Excludes built-in Databricks tokens to reduce false positives  \n",
    "- Provides detailed reporting with SHA-256 hashed secrets for security\n",
    "- Handles pagination for large workspaces\n",
    "- Includes proper error handling and rate limiting\n",
    "\n",
    "## Prerequisites\n",
    "- Databricks workspace with appropriate permissions\n",
    "- Access to install packages and run shell commands\n",
    "- Valid Databricks API token (automatically extracted from notebook context)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Install Dependencies and Setup TruffleHog\n",
    "\n",
    "This cell installs required Python packages and downloads TruffleHog binary. It also creates the custom detector configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh \n",
    "# Install required Python packages\n",
    "pip install requests pyyaml\n",
    "\n",
    "# Download and install TruffleHog binary to /tmp directory\n",
    "echo \"Installing TruffleHog...\"\n",
    "curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /tmp\n",
    "\n",
    "echo \"Setup completed successfully!\"\n",
    "echo \"TruffleHog binary location: /tmp/trufflehog\"\n",
    "echo \"Configuration will be loaded from: /Workspace/Repos/.../configs/trufflehog_detectors.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configuration and Authentication\n",
    "\n",
    "This cell sets up configuration constants and extracts Databricks authentication context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f00897-f0be-4e8d-b8da-f91c3cfa088a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import base64\n",
    "import subprocess\n",
    "import hashlib\n",
    "import logging\n",
    "import yaml\n",
    "from datetime import timedelta, datetime\n",
    "from urllib.parse import quote\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "# Configure logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_config_from_file():\n",
    "    \"\"\"Load configuration from the external YAML file in the configs directory.\"\"\"\n",
    "    try:\n",
    "        # Get the current notebook's directory and construct path to config file\n",
    "        notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "        repo_root = \"/\".join(notebook_path.split(\"/\")[:-3])  # Go up from notebooks/Includes/scan_secrets\n",
    "        config_path = f\"{repo_root}/configs/trufflehog_detectors.yaml\"\n",
    "        \n",
    "        logger.info(f\"Loading configuration from: {config_path}\")\n",
    "        \n",
    "        # Read the configuration file\n",
    "        with open(config_path, 'r') as file:\n",
    "            config_data = yaml.safe_load(file)\n",
    "        \n",
    "        return config_data\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not load external config file: {str(e)}\")\n",
    "        logger.info(\"Using default configuration\")\n",
    "        # Fallback to default configuration\n",
    "        return {\n",
    "            \"detectors\": [\n",
    "                {\"name\": \"DkeaToken\", \"keywords\": [\"dkea\"], \"regex\": {\"id\": \"(?i)\\\\b(dkea[a-h0-9]{32})\"}},\n",
    "                {\"name\": \"DapiToken\", \"keywords\": [\"dapi\"], \"regex\": {\"id\": \"(?i)\\\\b(dapi[a-h0-9]{32})\"}},\n",
    "                {\"name\": \"DoseToken\", \"keywords\": [\"dose\"], \"regex\": {\"id\": \"(?i)\\\\b(dose[a-h0-9]{32})\"}}\n",
    "            ],\n",
    "            \"settings\": {\n",
    "                \"excluded_detectors\": [\"DatabricksToken\"],\n",
    "                \"rate_limiting\": {\"api_sleep_seconds\": 10},\n",
    "                \"search_settings\": {\"page_size\": 50, \"days_back\": 1}\n",
    "            }\n",
    "        }\n",
    "\n",
    "def create_trufflehog_config(config_data: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create TruffleHog configuration file from loaded config data.\"\"\"\n",
    "    config_file_path = \"/tmp/trufflehog_config.yaml\"\n",
    "    \n",
    "    # Extract just the detectors section for TruffleHog\n",
    "    trufflehog_config = {\"detectors\": config_data.get(\"detectors\", [])}\n",
    "    \n",
    "    try:\n",
    "        with open(config_file_path, 'w') as file:\n",
    "            yaml.dump(trufflehog_config, file, default_flow_style=False)\n",
    "        \n",
    "        logger.info(f\"TruffleHog configuration created at: {config_file_path}\")\n",
    "        return config_file_path\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create TruffleHog config file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load configuration from external file\n",
    "config_data = load_config_from_file()\n",
    "\n",
    "# Configuration class using loaded values\n",
    "class Config:\n",
    "    \"\"\"Configuration class for TruffleHog scanning parameters\"\"\"\n",
    "    \n",
    "    # File paths\n",
    "    TRUFFLEHOG_BINARY = \"/tmp/trufflehog\"\n",
    "    TRUFFLEHOG_CONFIG = create_trufflehog_config(config_data)\n",
    "    TEMP_NOTEBOOKS_DIR = config_data.get(\"settings\", {}).get(\"file_paths\", {}).get(\"temp_notebooks\", \"/tmp/notebooks\")\n",
    "    RESULTS_LOG_FILE = config_data.get(\"settings\", {}).get(\"file_paths\", {}).get(\"results_log\", \"/tmp/trufflehog_scan_results.json\")\n",
    "    \n",
    "    # API settings from config\n",
    "    API_SLEEP_SECONDS = config_data.get(\"settings\", {}).get(\"rate_limiting\", {}).get(\"api_sleep_seconds\", 10)\n",
    "    PAGE_SIZE = config_data.get(\"settings\", {}).get(\"search_settings\", {}).get(\"page_size\", 50)\n",
    "    DAYS_BACK = config_data.get(\"settings\", {}).get(\"search_settings\", {}).get(\"days_back\", 1)\n",
    "    \n",
    "    # TruffleHog settings from config\n",
    "    EXCLUDED_DETECTORS = config_data.get(\"settings\", {}).get(\"excluded_detectors\", [\"DatabricksToken\"])\n",
    "    \n",
    "# Extract Databricks authentication context\n",
    "# These are automatically available in Databricks notebooks\n",
    "try:\n",
    "    token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)\n",
    "    base_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().getOrElse(None)\n",
    "    \n",
    "    if not token or not base_url:\n",
    "        raise ValueError(\"Unable to extract Databricks authentication context\")\n",
    "        \n",
    "    logger.info(f\"Successfully extracted Databricks context. Base URL: {base_url}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to extract Databricks context: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create temporary directories if they don't exist\n",
    "os.makedirs(Config.TEMP_NOTEBOOKS_DIR, exist_ok=True)\n",
    "logger.info(f\"Temporary directory created: {Config.TEMP_NOTEBOOKS_DIR}\")\n",
    "\n",
    "print(\"‚úÖ Configuration loaded from external file and authentication setup completed successfully!\")\n",
    "print(f\"üìÅ Config file: {Config.TRUFFLEHOG_CONFIG}\")\n",
    "print(f\"üîß Loaded {len(config_data.get('detectors', []))} custom detectors\")\n",
    "print(f\"‚öôÔ∏è  API sleep: {Config.API_SLEEP_SECONDS}s, Page size: {Config.PAGE_SIZE}, Days back: {Config.DAYS_BACK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Utility Functions\n",
    "\n",
    "This cell defines all the utility functions for API interactions, file operations, and secret scanning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions for TruffleHog Secret Scanning\n",
    "\n",
    "def get_yesterday_utc_midnight() -> int:\n",
    "    \"\"\"\n",
    "    Get yesterday's date in UTC at midnight as milliseconds timestamp.\n",
    "    \n",
    "    Returns:\n",
    "        int: Timestamp in milliseconds for yesterday at 00:00 UTC\n",
    "    \"\"\"\n",
    "    today_utc_midnight = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    yesterday_utc_midnight = today_utc_midnight - timedelta(days=Config.DAYS_BACK)\n",
    "    return int(yesterday_utc_midnight.timestamp() * 1000)\n",
    "\n",
    "def convert_time_to_databricks_format(env_time: int) -> int:\n",
    "    \"\"\"\n",
    "    Convert environment time to Databricks format.\n",
    "    \n",
    "    Args:\n",
    "        env_time (int): Time in milliseconds\n",
    "        \n",
    "    Returns:\n",
    "        int: Time in Databricks format (milliseconds)\n",
    "    \"\"\"\n",
    "    return int(env_time)\n",
    "\n",
    "def generate_sha256_hash(secret: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate SHA-256 hash of a secret for secure logging.\n",
    "    \n",
    "    Args:\n",
    "        secret (str): The secret string to hash\n",
    "        \n",
    "    Returns:\n",
    "        str: SHA-256 hash in hexadecimal format\n",
    "    \"\"\"\n",
    "    secret_bytes = secret.encode(\"utf-8\")\n",
    "    sha = hashlib.sha256()\n",
    "    sha.update(secret_bytes)\n",
    "    return sha.hexdigest()\n",
    "\n",
    "def make_api_request(url: str, headers: Dict[str, str], data: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Make API request to Databricks with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        url (str): API endpoint URL\n",
    "        headers (Dict[str, str]): Request headers\n",
    "        data (Optional[Dict[str, Any]]): Request payload\n",
    "        \n",
    "    Returns:\n",
    "        Optional[Dict[str, Any]]: JSON response or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, json=data, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        elif response.status_code == 429:\n",
    "            logger.warning(f\"Rate limit hit for URL: {url}. Waiting before retry...\")\n",
    "            time.sleep(Config.API_SLEEP_SECONDS * 2)  # Wait longer for rate limits\n",
    "            return None\n",
    "        else:\n",
    "            logger.warning(f\"API request failed. URL: {url}, Status: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Request timeout for URL: {url}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request error for URL: {url}. Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def check_notebook_status(notebook_path: str) -> int:\n",
    "    \"\"\"\n",
    "    Check if a notebook exists and is accessible.\n",
    "    \n",
    "    Args:\n",
    "        notebook_path (str): Path to the notebook\n",
    "        \n",
    "    Returns:\n",
    "        int: HTTP status code (200=accessible, 403=no permission, 404=not found)\n",
    "    \"\"\"\n",
    "    check_url = f\"{base_url}/api/2.0/workspace/get-status?path={notebook_path}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(check_url, headers=headers, timeout=30)\n",
    "        return response.status_code\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error checking notebook status for {notebook_path}: {str(e)}\")\n",
    "        return 500  # Internal server error\n",
    "\n",
    "def export_notebook_content(notebook_path: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Export notebook content from Databricks workspace.\n",
    "    \n",
    "    Args:\n",
    "        notebook_path (str): Path to the notebook\n",
    "        \n",
    "    Returns:\n",
    "        Optional[Dict[str, Any]]: Notebook export response or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        url = f\"{base_url}/api/2.0/workspace/export?path={notebook_path}\"\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error exporting notebook content for {notebook_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def decode_and_write_content(content: str, output_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Decode base64 content and write to file.\n",
    "    \n",
    "    Args:\n",
    "        content (str): Base64 encoded content\n",
    "        output_path (str): Path to write decoded content\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        decoded_content = base64.b64decode(content).decode(\"utf-8\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(decoded_content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing content to {output_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def scan_for_secrets(file_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Run TruffleHog scan on a file to detect secrets.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to file to scan\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: TruffleHog output in JSON format or None if error\n",
    "    \"\"\"\n",
    "    # Build TruffleHog command with proper configuration\n",
    "    excluded_detectors = \",\".join(Config.EXCLUDED_DETECTORS)\n",
    "    trufflehog_command = (\n",
    "        f\"{Config.TRUFFLEHOG_BINARY} filesystem {file_path} \"\n",
    "        f\"--exclude-detectors {excluded_detectors} \"\n",
    "        f\"--no-update --config {Config.TRUFFLEHOG_CONFIG} -j\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            trufflehog_command, \n",
    "            shell=True, \n",
    "            check=True, \n",
    "            capture_output=True, \n",
    "            text=True,\n",
    "            timeout=300  # 5 minute timeout\n",
    "        )\n",
    "        return result.stdout\n",
    "    except subprocess.TimeoutExpired:\n",
    "        logger.error(f\"TruffleHog scan timed out for file: {file_path}\")\n",
    "        return None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"TruffleHog scan failed for file: {file_path}. Error: {e}\")\n",
    "        if e.stderr:\n",
    "            logger.error(f\"TruffleHog stderr: {e.stderr}\")\n",
    "        return None\n",
    "\n",
    "def process_trufflehog_output(trufflehog_output: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Process TruffleHog JSON output and extract relevant information.\n",
    "    \n",
    "    Args:\n",
    "        trufflehog_output (str): Raw TruffleHog output in JSON format\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict[str, str]]: List of detected secrets with hashed values\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if not trufflehog_output or not trufflehog_output.strip():\n",
    "        return results\n",
    "    \n",
    "    for line in trufflehog_output.strip().splitlines():\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            detector_name = data.get(\"DetectorName\", \"Unknown\")\n",
    "            raw_value = data.get(\"Raw\", \"\")\n",
    "            \n",
    "            if raw_value:\n",
    "                # Generate SHA-256 hash for security (don't log actual secrets)\n",
    "                raw_sha = generate_sha256_hash(raw_value)\n",
    "                \n",
    "                # Add metadata about the detection\n",
    "                result = {\n",
    "                    \"DetectorName\": detector_name,\n",
    "                    \"Raw_SHA\": raw_sha,\n",
    "                    \"SourceFile\": data.get(\"SourceMetadata\", {}).get(\"Data\", {}).get(\"Filesystem\", {}).get(\"file\", \"Unknown\"),\n",
    "                    \"Verified\": data.get(\"Verified\", False)\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.warning(f\"Failed to parse TruffleHog output line: {line}. Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Utility functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Main Scanning Functions\n",
    "\n",
    "This cell contains the main functions for processing notebooks and orchestrating the secret scanning workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Scanning Functions\n",
    "\n",
    "def scan_notebook_for_secrets(notebook_path: str, object_id: str) -> Optional[List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Scan a single notebook for secrets using TruffleHog.\n",
    "    \n",
    "    Args:\n",
    "        notebook_path (str): Path to the notebook in Databricks workspace\n",
    "        object_id (str): Unique identifier for the notebook\n",
    "        \n",
    "    Returns:\n",
    "        Optional[List[Dict[str, str]]]: List of detected secrets or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if notebook exists and is accessible\n",
    "        notebook_status = check_notebook_status(notebook_path)\n",
    "        \n",
    "        if notebook_status == 200:\n",
    "            # Export notebook content\n",
    "            export_response = export_notebook_content(notebook_path)\n",
    "            if export_response is None:\n",
    "                logger.warning(f\"Failed to export notebook content: {notebook_path}\")\n",
    "                return None\n",
    "                \n",
    "            content = export_response.get(\"content\")\n",
    "            if not content:\n",
    "                logger.warning(f\"No content found in notebook: {notebook_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Write content to temporary file\n",
    "            output_file_path = os.path.join(Config.TEMP_NOTEBOOKS_DIR, f\"notebook_content_{object_id}.txt\")\n",
    "            if not decode_and_write_content(content, output_file_path):\n",
    "                logger.error(f\"Failed to write notebook content to file: {output_file_path}\")\n",
    "                return None\n",
    "                \n",
    "            logger.info(f\"Notebook content exported to: {output_file_path}\")\n",
    "            \n",
    "            # Scan for secrets using TruffleHog\n",
    "            trufflehog_output = scan_for_secrets(output_file_path)\n",
    "            if trufflehog_output is None:\n",
    "                logger.warning(f\"TruffleHog scan failed for: {notebook_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Process TruffleHog output\n",
    "            results = process_trufflehog_output(trufflehog_output)\n",
    "            \n",
    "            if results:\n",
    "                logger.info(f\"Found {len(results)} potential secrets in notebook: {notebook_path}\")\n",
    "                # Log results securely (with hashed secrets)\n",
    "                for result in results:\n",
    "                    logger.info(f\"Secret detected - Type: {result['DetectorName']}, SHA: {result['Raw_SHA'][:16]}...\")\n",
    "            else:\n",
    "                logger.info(f\"No secrets found in notebook: {notebook_path}\")\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            try:\n",
    "                os.remove(output_file_path)\n",
    "            except OSError as e:\n",
    "                logger.warning(f\"Failed to clean up temporary file {output_file_path}: {str(e)}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        elif notebook_status == 403:\n",
    "            logger.warning(f\"Access denied for notebook: {notebook_path}\")\n",
    "            return None\n",
    "        elif notebook_status == 404:\n",
    "            logger.warning(f\"Notebook not found: {notebook_path}\")\n",
    "            return None\n",
    "        else:\n",
    "            logger.warning(f\"Unexpected status {notebook_status} for notebook: {notebook_path}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scanning notebook {notebook_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_search_response(response: Dict[str, Any], results_list: List[Dict[str, Any]], \n",
    "                          output_filename: Optional[str] = None) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Process search API response and scan notebooks for secrets.\n",
    "    \n",
    "    Args:\n",
    "        response (Dict[str, Any]): API response from unified search\n",
    "        results_list (List[Dict[str, Any]]): List to store notebook metadata\n",
    "        output_filename (Optional[str]): File to log notebook metadata\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: Next page token for pagination or None if no more pages\n",
    "    \"\"\"\n",
    "    if not response:\n",
    "        logger.warning(\"Empty response received\")\n",
    "        return None\n",
    "        \n",
    "    results = response.get(\"results\", [])\n",
    "    logger.info(f\"Processing {len(results)} notebooks from search response\")\n",
    "    \n",
    "    for notebook in results:\n",
    "        notebook_id = notebook.get(\"id\", \"\")\n",
    "        notebook_name = notebook.get(\"name\", \"\")\n",
    "        parent_path = notebook.get(\"workspace_path\", \"\")\n",
    "        \n",
    "        if not notebook_id or not notebook_name:\n",
    "            logger.warning(\"Skipping notebook with missing ID or name\")\n",
    "            continue\n",
    "            \n",
    "        # Construct full notebook path\n",
    "        temp_path = f\"{parent_path}/{notebook_name}\"\n",
    "        path = quote(temp_path)\n",
    "        \n",
    "        logger.info(f\"Processing notebook: {notebook_id} - {temp_path}\")\n",
    "        \n",
    "        # Store notebook metadata\n",
    "        notebook_metadata = {\"object_id\": notebook_id, \"path\": path, \"name\": notebook_name}\n",
    "        results_list.append(notebook_metadata)\n",
    "        \n",
    "        # Log to file if specified\n",
    "        if output_filename:\n",
    "            try:\n",
    "                with open(output_filename, mode=\"a\", encoding=\"utf-8\") as output_file:\n",
    "                    json.dump(notebook_metadata, output_file)\n",
    "                    output_file.write(\"\\n\")\n",
    "            except IOError as e:\n",
    "                logger.error(f\"Failed to write to output file {output_filename}: {str(e)}\")\n",
    "        \n",
    "        # Scan notebook for secrets\n",
    "        secret_results = scan_notebook_for_secrets(path, notebook_id)\n",
    "        \n",
    "        if secret_results:\n",
    "            # Store results with notebook metadata\n",
    "            notebook_metadata[\"secrets_found\"] = len(secret_results)\n",
    "            notebook_metadata[\"secret_details\"] = secret_results\n",
    "            \n",
    "            # Log summary\n",
    "            print(f\"üö® SECRETS DETECTED in {temp_path}:\")\n",
    "            print(json.dumps(secret_results, indent=2))\n",
    "        else:\n",
    "            notebook_metadata[\"secrets_found\"] = 0\n",
    "            print(f\"‚úÖ No secrets found in {temp_path}\")\n",
    "    \n",
    "    # Return next page token for pagination\n",
    "    return response.get(\"next_page_token\")\n",
    "\n",
    "print(\"‚úÖ Main scanning functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Execute Secret Scanning\n",
    "\n",
    "This cell executes the main scanning workflow to search for notebooks and scan them for secrets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute TruffleHog Secret Scanning Workflow\n",
    "\n",
    "def main_scanning_workflow():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the secret scanning process.\n",
    "    \"\"\"\n",
    "    print(\"üîç Starting TruffleHog Secret Scanning Workflow\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get time range for notebook search\n",
    "    # Use environment variable TIME if provided, otherwise use yesterday's midnight\n",
    "    env_time = os.environ.get(\"TIME\")\n",
    "    if env_time:\n",
    "        try:\n",
    "            last_edited_after = convert_time_to_databricks_format(int(env_time))\n",
    "            logger.info(f\"Using provided TIME environment variable: {env_time}\")\n",
    "        except ValueError:\n",
    "            logger.warning(f\"Invalid TIME environment variable: {env_time}. Using default.\")\n",
    "            last_edited_after = get_yesterday_utc_midnight()\n",
    "    else:\n",
    "        last_edited_after = get_yesterday_utc_midnight()\n",
    "        logger.info(f\"Using default time range: last {Config.DAYS_BACK} day(s)\")\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    results_list = []\n",
    "    total_notebooks_processed = 0\n",
    "    total_secrets_found = 0\n",
    "    notebooks_with_secrets = 0\n",
    "    \n",
    "    # Setup API request parameters\n",
    "    url = f\"{base_url}/api/2.0/search-midtier/unified-search\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"query\": {\"query\": \"\"},\n",
    "        \"filters\": {\"result_types\": [\"NOTEBOOK\"], \"last_edited_after\": last_edited_after},\n",
    "        \"page_size\": Config.PAGE_SIZE,\n",
    "    }\n",
    "    \n",
    "    print(f\"üìÖ Searching for notebooks modified after: {datetime.fromtimestamp(last_edited_after/1000).strftime('%Y-%m-%d %H:%M:%S UTC')}\")\n",
    "    print(f\"üìÑ Page size: {Config.PAGE_SIZE}\")\n",
    "    print()\n",
    "    \n",
    "    # Pagination loop\n",
    "    next_page_token = \"\"  # Start with empty token\n",
    "    page_number = 1\n",
    "    \n",
    "    try:\n",
    "        while next_page_token is not None:\n",
    "            print(f\"üìñ Processing page {page_number}...\")\n",
    "            \n",
    "            # Add pagination token to request\n",
    "            if next_page_token:\n",
    "                data[\"page_token\"] = next_page_token\n",
    "            elif \"page_token\" in data:\n",
    "                del data[\"page_token\"]  # Remove token for first request\n",
    "            \n",
    "            # Make API request\n",
    "            response = make_api_request(url, headers, data)\n",
    "            \n",
    "            if response is None:\n",
    "                logger.warning(f\"Failed to get response for page {page_number}\")\n",
    "                break\n",
    "            \n",
    "            # Process response and scan notebooks\n",
    "            page_start_time = time.time()\n",
    "            next_page_token = process_search_response(response, results_list, Config.RESULTS_LOG_FILE)\n",
    "            page_end_time = time.time()\n",
    "            \n",
    "            # Update counters\n",
    "            page_notebooks = len(response.get(\"results\", []))\n",
    "            total_notebooks_processed += page_notebooks\n",
    "            \n",
    "            # Count secrets found in this page\n",
    "            page_secrets = sum(1 for notebook in results_list[-page_notebooks:] if notebook.get(\"secrets_found\", 0) > 0)\n",
    "            notebooks_with_secrets += page_secrets\n",
    "            total_secrets_found += sum(notebook.get(\"secrets_found\", 0) for notebook in results_list[-page_notebooks:])\n",
    "            \n",
    "            print(f\"   ‚è±Ô∏è  Page {page_number} completed in {page_end_time - page_start_time:.2f} seconds\")\n",
    "            print(f\"   üìä Notebooks processed: {page_notebooks}, Secrets found: {sum(notebook.get('secrets_found', 0) for notebook in results_list[-page_notebooks:])}\")\n",
    "            print()\n",
    "            \n",
    "            page_number += 1\n",
    "            \n",
    "            # Rate limiting - sleep between API calls\n",
    "            if next_page_token is not None:\n",
    "                logger.info(f\"Sleeping for {Config.API_SLEEP_SECONDS} seconds to prevent rate limiting...\")\n",
    "                time.sleep(Config.API_SLEEP_SECONDS)\n",
    "        \n",
    "        # Final summary\n",
    "        print(\"üéâ Secret Scanning Completed!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üìä Total notebooks processed: {total_notebooks_processed}\")\n",
    "        print(f\"üîç Notebooks with secrets: {notebooks_with_secrets}\")\n",
    "        print(f\"üö® Total secrets detected: {total_secrets_found}\")\n",
    "        \n",
    "        if notebooks_with_secrets > 0:\n",
    "            print(f\"‚ö†Ô∏è  Security Alert: {notebooks_with_secrets} notebook(s) contain potential secrets!\")\n",
    "            print(\"   Please review the detailed results above and take appropriate action.\")\n",
    "        else:\n",
    "            print(\"‚úÖ No secrets detected in any notebooks. Great job!\")\n",
    "        \n",
    "        print(f\"üìù Detailed results logged to: {Config.RESULTS_LOG_FILE}\")\n",
    "        \n",
    "        # Return summary statistics\n",
    "        return {\n",
    "            \"total_notebooks\": total_notebooks_processed,\n",
    "            \"notebooks_with_secrets\": notebooks_with_secrets,\n",
    "            \"total_secrets\": total_secrets_found,\n",
    "            \"results\": results_list\n",
    "        }\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Scanning interrupted by user\")\n",
    "        logger.info(\"Scanning workflow interrupted by user\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in scanning workflow: {str(e)}\")\n",
    "        print(f\"‚ùå Error occurred during scanning: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Execute the scanning workflow\n",
    "if __name__ == \"__main__\":\n",
    "    scan_results = main_scanning_workflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ddf9ac-81a3-439a-a9b3-8498583231fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Results Analysis and Cleanup\n",
    "\n",
    "# Display scan results summary if available\n",
    "if 'scan_results' in locals() and scan_results:\n",
    "    print(\"üìà Detailed Scan Results Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Group results by secret type\n",
    "    secret_types = {}\n",
    "    for notebook in scan_results.get(\"results\", []):\n",
    "        if notebook.get(\"secrets_found\", 0) > 0:\n",
    "            for secret in notebook.get(\"secret_details\", []):\n",
    "                detector_name = secret.get(\"DetectorName\", \"Unknown\")\n",
    "                if detector_name not in secret_types:\n",
    "                    secret_types[detector_name] = 0\n",
    "                secret_types[detector_name] += 1\n",
    "    \n",
    "    if secret_types:\n",
    "        print(\"üîç Secret Types Detected:\")\n",
    "        for secret_type, count in sorted(secret_types.items()):\n",
    "            print(f\"   ‚Ä¢ {secret_type}: {count} occurrence(s)\")\n",
    "        print()\n",
    "    \n",
    "    # Show notebooks with most secrets\n",
    "    notebooks_by_secrets = sorted(\n",
    "        [nb for nb in scan_results.get(\"results\", []) if nb.get(\"secrets_found\", 0) > 0],\n",
    "        key=lambda x: x.get(\"secrets_found\", 0),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    if notebooks_by_secrets:\n",
    "        print(\"üìö Top Notebooks with Secrets:\")\n",
    "        for i, notebook in enumerate(notebooks_by_secrets[:5]):  # Show top 5\n",
    "            print(f\"   {i+1}. {notebook.get('name', 'Unknown')} - {notebook.get('secrets_found', 0)} secret(s)\")\n",
    "        print()\n",
    "\n",
    "# Cleanup and file operations\n",
    "print(\"üßπ Cleanup Operations\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# List temporary files created\n",
    "print(\"üìÅ Temporary files in /tmp/notebooks:\")\n",
    "%sh ls -la /tmp/notebooks/ 2>/dev/null || echo \"Directory not found or empty\"\n",
    "\n",
    "print(\"\\nüìÑ Configuration files:\")\n",
    "%sh ls -la /tmp/trufflehog* 2>/dev/null || echo \"No TruffleHog config files found\"\n",
    "\n",
    "print(\"\\nüìä Results log file:\")\n",
    "%sh ls -la /tmp/trufflehog_scan_results.json 2>/dev/null || echo \"No results log file found\"\n",
    "\n",
    "print(\"\\n‚úÖ Cleanup completed. Temporary files will be automatically removed when the cluster terminates.\")\n",
    "\n",
    "# Display final recommendations\n",
    "print(\"\\nüéØ Next Steps and Recommendations\")\n",
    "print(\"=\" * 40)\n",
    "print(\"1. üîç Review any detected secrets immediately\")\n",
    "print(\"2. üîÑ Rotate any exposed credentials\")\n",
    "print(\"3. üìù Update notebooks to remove hardcoded secrets\")\n",
    "print(\"4. üîê Use Databricks secrets or environment variables instead\")\n",
    "print(\"5. üìÖ Schedule regular secret scans as part of your security workflow\")\n",
    "print(\"6. üìã Consider integrating this scan into your CI/CD pipeline\")\n",
    "\n",
    "if 'scan_results' in locals() and scan_results and scan_results.get(\"notebooks_with_secrets\", 0) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  IMMEDIATE ACTION REQUIRED:\")\n",
    "    print(\"   Secrets were detected in your notebooks. Please address them promptly!\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No immediate action required - no secrets detected.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1828314051772642,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "trufflehog_scan",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
